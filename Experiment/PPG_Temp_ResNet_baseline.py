import os
import glob
import numpy as np
import pandas as pd
import torch
from torch.utils.data import Dataset, DataLoader
from scipy import signal

class MultiModalDataset(Dataset):
    def __init__(self, data_folder, window_size=300, stride=50, fs=128):
        self.window_size = window_size
        self.stride = stride
        self.fs = fs
        
        self.samples_ppg = []
        self.samples_temp = []
        self.labels = []
        
        # 1. íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ë¡œë“œ
        search_pattern = os.path.join(data_folder, "user_*.csv")
        file_list = glob.glob(search_pattern)
        
        if not file_list:
            print(f"âŒ ê²½ê³ : '{data_folder}' ê²½ë¡œì—ì„œ íŒŒì¼ì„ í•˜ë‚˜ë„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return

        print(f"ğŸ“‚ ë°ì´í„° ë¡œë”© ì‹œì‘... (ì´ {len(file_list)}ê°œ íŒŒì¼ ê°ì§€)")
        
        for filepath in file_list:
            filename = os.path.basename(filepath)
            
            # 2. User ID ì¶”ì¶œ (íŒŒì¼ëª… íŒŒì‹±)
            try:
                # user_4_part1_final.csv -> user, 4, part1, final.csv
                parts = filename.split('_')
                user_num = int(parts[1]) # 4 ì¶”ì¶œ
                label = user_num - 1     # 0-based index
            except Exception as e:
                print(f"âš ï¸ íŒŒì¼ëª… íŒŒì‹± ì‹¤íŒ¨ ({filename}): {e}")
                continue

            # 3. CSV ì½ê¸° ë° ì „ì²˜ë¦¬
            try:
                df = pd.read_csv(filepath)
                
                # [ìˆ˜ì • ì™„ë£Œ] í™•ì¸ëœ ì»¬ëŸ¼ëª… ì§ì ‘ ì‚¬ìš© ('Index', 'PPG', 'temperature')
                # í˜¹ì‹œ ëª¨ë¥¼ ê³µë°± ì œê±°ë¥¼ ìœ„í•´ ì»¬ëŸ¼ëª… strip ì²˜ë¦¬
                df.columns = [c.strip() for c in df.columns]
                
                if 'PPG' not in df.columns or 'temperature' not in df.columns:
                     print(f"  âŒ ì»¬ëŸ¼ ëˆ„ë½ ({filename}): {df.columns}")
                     continue

                raw_ppg = df['PPG'].values
                raw_temp = df['temperature'].values
                
                # ì „ì²˜ë¦¬: Detrending -> 4Hz Low-pass Filter
                processed_ppg = self.preprocess_ppg(raw_ppg)
                
                # ì˜¨ë„ ì •ê·œí™” (Min-Max Scaling: 25~40ë„ ê¸°ì¤€)
                processed_temp = (raw_temp - 25.0) / (40.0 - 25.0) 

                # 4. ìŠ¬ë¼ì´ë”© ìœˆë„ìš°
                num_windows = (len(processed_ppg) - self.window_size) // self.stride
                
                if num_windows <= 0:
                    continue

                file_samples = 0
                for i in range(num_windows):
                    start = i * self.stride
                    end = start + self.window_size
                    
                    ppg_window = processed_ppg[start:end]
                    temp_window = processed_temp[start:end]
                    
                    # (Optional) ì´ìƒì¹˜ ì œê±° (PPG Z-score > 5)
                    if np.max(np.abs(ppg_window)) > 5:
                        continue
                        
                    self.samples_ppg.append(ppg_window)
                    self.samples_temp.append(temp_window)
                    self.labels.append(label)
                    file_samples += 1
                
                print(f"  âœ… User {user_num} (Label {label}): {file_samples} windows loaded.")
                
            except Exception as e:
                print(f"  âŒ ë°ì´í„° ë¡œë“œ ì—ëŸ¬ ({filename}): {e}")

        # ë¦¬ìŠ¤íŠ¸ -> Numpy -> Tensor
        self.samples_ppg = np.array(self.samples_ppg, dtype=np.float32)
        self.samples_temp = np.array(self.samples_temp, dtype=np.float32)
        self.labels = np.array(self.labels, dtype=np.int64)
        
        # ì°¨ì› í™•ì¥: (N, 1, Length)
        if len(self.labels) > 0:
            self.samples_ppg = np.expand_dims(self.samples_ppg, axis=1)
            self.samples_temp = np.expand_dims(self.samples_temp, axis=1)

        print(f"ğŸ‰ ì „ì²´ ë°ì´í„° ë¡œë“œ ì™„ë£Œ! ì´ ìƒ˜í”Œ ìˆ˜: {len(self.labels)}")

    def preprocess_ppg(self, signal_data):
        # 1. Detrending
        detrended = signal.detrend(signal_data)
        # 2. Low-pass Filter (4Hz)
        nyquist = 0.5 * self.fs
        cutoff = 4.0 / nyquist
        b, a = signal.butter(4, cutoff, btype='low')
        filtered = signal.filtfilt(b, a, detrended)
        # 3. Z-score Normalization
        normalized = (filtered - np.mean(filtered)) / (np.std(filtered) + 1e-6)
        return normalized

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        return (torch.from_numpy(self.samples_ppg[idx]), 
                torch.from_numpy(self.samples_temp[idx])), torch.tensor(self.labels[idx])
    

if __name__ == "__main__":
    data_folder = "./data/PPG_ECG_Data"
    
    # ìœˆë„ìš° í¬ê¸° 300 (ë…¼ë¬¸ ê¸°ì¤€), ìŠ¤íŠ¸ë¼ì´ë“œ 50 (ê²¹ì³ì„œ ë°ì´í„° ì¦ê°• íš¨ê³¼)
    dataset = MultiModalDataset(data_folder, window_size=300, stride=50)
    
    # DataLoader ìƒì„±
    dataloader = DataLoader(dataset, batch_size=64, shuffle=True)

    # ë°ì´í„° í˜•ìƒ í™•ì¸
    if len(dataset) > 0:
        (ppg, temp), label = next(iter(dataloader))
        print("\n--- Batch Shape Check ---")
        print(f"PPG Input Shape : {ppg.shape}")   # (64, 1, 300)
        print(f"Temp Input Shape: {temp.shape}")  # (64, 1, 300)
        print(f"Label Shape     : {label.shape}") # (64,)


import torch
import torch.nn as nn
import torch.nn.functional as F

# ==========================================
# 1. ResNet Backbone (Feature Extractor)
# ==========================================
class BasicBlock1D(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1):
        super(BasicBlock1D, self).__init__()
        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm1d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm1d(out_channels)
        
        self.shortcut = nn.Sequential()
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm1d(out_channels)
            )

    def forward(self, x):
        out = self.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += self.shortcut(x)
        out = self.relu(out)
        return out

class ResNetEncoder(nn.Module):
    def __init__(self, in_channels=1, d_model=128): # d_modelì„ 128ë¡œ ìƒí–¥
        super(ResNetEncoder, self).__init__()
        
        # Initial Conv
        self.conv1 = nn.Conv1d(in_channels, 32, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = nn.BatchNorm1d(32)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)
        
        # ResNet Layers
        self.layer1 = self._make_layer(32, 32, 2, stride=1)
        self.layer2 = self._make_layer(32, 64, 2, stride=2)
        self.layer3 = self._make_layer(64, d_model, 2, stride=2) 
        # Layer 4 ì œê±° ë˜ëŠ” ì¡°ì • (ì‹œí€€ìŠ¤ ê¸¸ì´ê°€ ë„ˆë¬´ ì¤„ì–´ë“¤ì§€ ì•Šë„ë¡)
        
        # Global Pooling (ë‚˜ì¤‘ì— ì‚¬ìš©)
        self.pool = nn.AdaptiveAvgPool1d(1)

    def _make_layer(self, in_planes, out_planes, blocks, stride):
        layers = []
        layers.append(BasicBlock1D(in_planes, out_planes, stride))
        for _ in range(1, blocks):
            layers.append(BasicBlock1D(out_planes, out_planes))
        return nn.Sequential(*layers)

    def forward(self, x):
        # x: (B, 1, 300)
        x = self.relu(self.bn1(self.conv1(x)))
        x = self.maxpool(x) # (B, 32, 75)
        
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x) # (B, 128, 19) -> ì‹œí€€ìŠ¤ ê¸¸ì´ê°€ 19ë¡œ ì¤„ì–´ë“¦
        
        # Cross-Attentionì„ ìœ„í•´ (B, Length, Channel) í˜•íƒœë¡œ ë³€í™˜
        # (B, 128, 19) -> (B, 19, 128)
        seq_out = x.transpose(1, 2)
        
        # Global Pooling for Vector representation
        pooled_out = self.pool(x).squeeze(-1) # (B, 128)
        
        return pooled_out, seq_out

# ==========================================
# 2. ResNet + Cross-Attention Fusion Model
# ==========================================
class ResNetFusionModel(nn.Module):
    def __init__(self, num_users=16, d_model=128, num_heads=4):
        super(ResNetFusionModel, self).__init__()
        
        # ResNet Backbone ì‚¬ìš© (PPG & Temp ê°ê°)
        self.ppg_encoder = ResNetEncoder(in_channels=1, d_model=d_model)
        self.temp_encoder = ResNetEncoder(in_channels=1, d_model=d_model)
        
        # Cross-Modal Attention (ë…¼ë¬¸ êµ¬ì¡° ìœ ì§€)
        self.cross_att = nn.MultiheadAttention(d_model, num_heads=num_heads, batch_first=True)
        
        self.norm_p = nn.LayerNorm(d_model)
        self.norm_t = nn.LayerNorm(d_model)
        
        # Fusion & Classifier
        self.fusion_fc = nn.Linear(d_model, d_model)
        self.classifier = nn.Sequential(
            nn.Linear(d_model, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, num_users)
        )

    def forward(self, x_ppg, x_temp):
        # 1. Encoding (ResNet)
        z_p, seq_p = self.ppg_encoder(x_ppg) # z: (B, 128), seq: (B, 19, 128)
        z_t, seq_t = self.temp_encoder(x_temp)
        
        # 2. Cross-Attention
        # QueryëŠ” Global Vector(z)ë¥¼ ì‹œí€€ìŠ¤í™”í•´ì„œ ì‚¬ìš©: (B, 1, 128)
        query_p = z_p.unsqueeze(1)
        query_t = z_t.unsqueeze(1)
        
        # Key, ValueëŠ” ì‹œí€€ìŠ¤ ì „ì²´(seq)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë””í…Œì¼í•œ ì •ë³´ë¥¼ ì°¸ì¡°
        # PPGê°€ Temperatureì˜ ì „ì²´ íë¦„(seq_t)ì„ ì°¸ì¡°
        attn_out_p, _ = self.cross_att(query_p, seq_t, seq_t) 
        z_p_refined = self.norm_p(z_p + attn_out_p.squeeze(1))
        
        # Temperatureê°€ PPGì˜ ì „ì²´ íë¦„(seq_p)ì„ ì°¸ì¡°
        attn_out_t, _ = self.cross_att(query_t, seq_p, seq_p)
        z_t_refined = self.norm_t(z_t + attn_out_t.squeeze(1))
        
        # 3. Fusion
        z_fused = z_p_refined + z_t_refined
        z_fused = F.relu(self.fusion_fc(z_fused))
        
        # 4. Classification
        logits = self.classifier(z_fused)
        
        return logits, z_p_refined, z_t_refined
    

# ==========================================
# 3. ì „ì²´ ëª¨ë¸ (Fusion & Classifier)
# ==========================================
class CrossAttentionFusion(nn.Module):
    def __init__(self, num_users=16, d_model=64, num_heads=4):
        super(CrossAttentionFusion, self).__init__()
        
        # ë“€ì–¼ ì¸ì½”ë” (PPGìš©, Tempìš©)
        self.ppg_encoder = ResNetEncoder(d_model=d_model)
        self.temp_encoder = ResNetEncoder(d_model=d_model)
        
        # Cross-Modal Attention
        self.cross_att = nn.MultiheadAttention(d_model, num_heads=num_heads, batch_first=True)
        
        self.norm_p = nn.LayerNorm(d_model)
        self.norm_t = nn.LayerNorm(d_model)
        
        # Fusion & Classifier
        self.fusion_fc = nn.Linear(d_model, d_model)
        self.classifier = nn.Sequential(
            nn.Linear(d_model, d_model // 2),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(d_model // 2, num_users)
        )

    def forward(self, x_ppg, x_temp):
        # 1. ì¸ì½”ë”©
        z_p, seq_p = self.ppg_encoder(x_ppg) # z: (B, D), seq: (B, L, D)
        z_t, seq_t = self.temp_encoder(x_temp)
        
        # 2. Cross-Attentionì„ ìœ„í•œ ì°¨ì› ì¡°ì • (B, 1, D)
        query_p = z_p.unsqueeze(1)
        query_t = z_t.unsqueeze(1)
        
        # PPGê°€ Tempë¥¼ ì°¸ì¡°í•˜ì—¬ ë³´ì •
        attn_out_p, _ = self.cross_att(query_p, query_t, query_t)
        z_p_refined = self.norm_p(z_p + attn_out_p.squeeze(1))
        
        # Tempê°€ PPGë¥¼ ì°¸ì¡°í•˜ì—¬ ë³´ì •
        attn_out_t, _ = self.cross_att(query_t, query_p, query_p)
        z_t_refined = self.norm_t(z_t + attn_out_t.squeeze(1))
        
        # 3. Fusion (Element-wise Addition)
        z_fused = z_p_refined + z_t_refined
        z_fused = F.relu(self.fusion_fc(z_fused))
        
        # 4. Classification
        logits = self.classifier(z_fused)
        
        return logits, z_p_refined, z_t_refined
    

class AlignmentLoss(nn.Module):
    def __init__(self, temperature=0.07):
        super(AlignmentLoss, self).__init__()
        self.temperature = temperature
        self.ce_loss = nn.CrossEntropyLoss()

    def forward(self, z_a, z_b):
        # z_a, z_b: (Batch, D)
        # Cosine Similarity ê³„ì‚°
        z_a = F.normalize(z_a, dim=1)
        z_b = F.normalize(z_b, dim=1)
        
        # (B, D) @ (D, B) -> (B, B) ìœ ì‚¬ë„ í–‰ë ¬
        logits = torch.matmul(z_a, z_b.T) / self.temperature
        
        # ì •ë‹µ: ëŒ€ê°ì„  ìš”ì†Œ (ìê¸° ìì‹ ê³¼ì˜ ìŒ)
        labels = torch.arange(z_a.size(0)).to(z_a.device)
        
        return self.ce_loss(logits, labels)

class SpreadControlLoss(nn.Module):
    def __init__(self, threshold=0.001):
        super(SpreadControlLoss, self).__init__()
        self.threshold = threshold

    def forward(self, z):
        # íŠ¹ì§• ë²¡í„°ë“¤ì˜ ë¶„ì‚°ì´ ë„ˆë¬´ ì»¤ì§€ì§€ ì•Šë„ë¡ ì œì–´
        z = F.normalize(z, dim=1)
        var = torch.var(z, dim=0).mean()
        # ë¶„ì‚°ì´ thresholdë³´ë‹¤ í¬ë©´ í˜ë„í‹°
        loss = F.relu(var - self.threshold)
        return loss


import torch.optim as optim
from tqdm.auto import tqdm  # Jupyter/Console ìë™ ê°ì§€

# ==========================================
# ì„¤ì • (Hyperparameters)
# ==========================================
NUM_USERS = 16  
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

LAMBDA_A = 0.5  
LAMBDA_S = 0.01 
LR = 0.001
EPOCHS = 30   

print(f"ğŸš€ í•™ìŠµ ì¥ì¹˜: {DEVICE}")

# ==========================================
# ëª¨ë¸ ë° í•™ìŠµ ì¤€ë¹„
# ==========================================
model = CrossAttentionFusion(num_users=NUM_USERS).to(DEVICE)

criterion_cls = nn.CrossEntropyLoss()
criterion_align = AlignmentLoss()
criterion_spread = SpreadControlLoss()

optimizer = optim.Adam(model.parameters(), lr=LR)

# ==========================================
# í•™ìŠµ ì‹¤í–‰
# ==========================================
model.train()

for epoch in range(EPOCHS):
    total_loss = 0
    correct = 0
    total_samples = 0
    
    # DataLoaderë¥¼ tqdmìœ¼ë¡œ ê°ì‹¸ì„œ ì§„í–‰ë¥  ë°” ìƒì„±
    # desc: ë°” ì™¼ìª½ì— í‘œì‹œë  ì„¤ëª… (Epoch ë²ˆí˜¸)
    progress_bar = tqdm(dataloader, desc=f"Epoch {epoch+1}/{EPOCHS}", leave=True)
    
    for batch_idx, ((ppg, temp), labels) in enumerate(progress_bar):
        # ë°ì´í„° GPUë¡œ ì´ë™
        ppg = ppg.to(DEVICE)
        temp = temp.to(DEVICE)
        labels = labels.to(DEVICE)
        
        optimizer.zero_grad()
        
        # 1. Forward
        outputs, z_p, z_t = model(ppg, temp)
        
        # 2. Loss ê³„ì‚°
        loss_cls = criterion_cls(outputs, labels)
        
        # ì •ë ¬ ì†ì‹¤ (Alignment: ì–‘ë°©í–¥)
        loss_align = criterion_align(z_p, z_t) + criterion_align(z_t, z_p)
        
        # ë¶„ì‚° ì œì–´ ì†ì‹¤ (Spread)
        loss_spread = criterion_spread(z_p) + criterion_spread(z_t)
        
        # ìµœì¢… Loss í•©ì‚°
        loss = loss_cls + (LAMBDA_A * loss_align) + (LAMBDA_S * loss_spread)
        
        # 3. Backward & Update
        loss.backward()
        optimizer.step()
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        total_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        total_samples += labels.size(0)
        correct += (predicted == labels).sum().item()
        
        # ì‹¤ì‹œê°„ ì •í™•ë„ ê³„ì‚°
        current_acc = 100 * correct / total_samples
        
        # TQDM ë°” ìš°ì¸¡ì— ì‹¤ì‹œê°„ ì •ë³´ í‘œì‹œ (Loss, Accuracy)
        progress_bar.set_postfix({
            'Loss': f"{loss.item():.4f}",
            'Acc': f"{current_acc:.2f}%",
            'Cls': f"{loss_cls.item():.4f}" # ë¶„ë¥˜ Lossë§Œ ë”°ë¡œ ë³´ê³  ì‹¶ë‹¤ë©´ ì¶”ê°€
        })

    # ì—í­ ì¢…ë£Œ í›„ í‰ê·  ê¸°ë¡ ì¶œë ¥
    avg_loss = total_loss / len(dataloader)
    final_acc = 100 * correct / total_samples
    print(f"âœ¨ Epoch {epoch+1} Summary - Avg Loss: {avg_loss:.4f}, Accuracy: {final_acc:.2f}%")

print("ğŸ ëª¨ë“  í•™ìŠµ ì™„ë£Œ!")