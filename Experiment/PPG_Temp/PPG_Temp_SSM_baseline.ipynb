{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8521b897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23bc9861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Index', 'PPG', 'temperature', 'ECG'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"/Data/CRS25/PPG_Certifiation/data/PPG_ECG_Data/user_1_final.csv\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af8e2e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy import signal\n",
    "\n",
    "class MultiModalDataset(Dataset):\n",
    "    def __init__(self, data_folder, window_size=300, stride=50, fs=128):\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.fs = fs\n",
    "        \n",
    "        self.samples_ppg = []\n",
    "        self.samples_temp = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # 1. íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ë¡œë“œ\n",
    "        search_pattern = os.path.join(data_folder, \"user_*.csv\")\n",
    "        file_list = glob.glob(search_pattern)\n",
    "        \n",
    "        if not file_list:\n",
    "            print(f\"âŒ ê²½ê³ : '{data_folder}' ê²½ë¡œì—ì„œ íŒŒì¼ì„ í•˜ë‚˜ë„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
    "            return\n",
    "\n",
    "        print(f\"ğŸ“‚ ë°ì´í„° ë¡œë”© ì‹œì‘... (ì´ {len(file_list)}ê°œ íŒŒì¼ ê°ì§€)\")\n",
    "        \n",
    "        for filepath in file_list:\n",
    "            filename = os.path.basename(filepath)\n",
    "            \n",
    "            # 2. User ID ì¶”ì¶œ (íŒŒì¼ëª… íŒŒì‹±)\n",
    "            try:\n",
    "                # user_4_part1_final.csv -> user, 4, part1, final.csv\n",
    "                parts = filename.split('_')\n",
    "                user_num = int(parts[1]) # 4 ì¶”ì¶œ\n",
    "                label = user_num - 1     # 0-based index\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ íŒŒì¼ëª… íŒŒì‹± ì‹¤íŒ¨ ({filename}): {e}\")\n",
    "                continue\n",
    "\n",
    "            # 3. CSV ì½ê¸° ë° ì „ì²˜ë¦¬\n",
    "            try:\n",
    "                df = pd.read_csv(filepath)\n",
    "                \n",
    "                # [ìˆ˜ì • ì™„ë£Œ] í™•ì¸ëœ ì»¬ëŸ¼ëª… ì§ì ‘ ì‚¬ìš© ('Index', 'PPG', 'temperature')\n",
    "                # í˜¹ì‹œ ëª¨ë¥¼ ê³µë°± ì œê±°ë¥¼ ìœ„í•´ ì»¬ëŸ¼ëª… strip ì²˜ë¦¬\n",
    "                df.columns = [c.strip() for c in df.columns]\n",
    "                \n",
    "                if 'PPG' not in df.columns or 'temperature' not in df.columns:\n",
    "                     print(f\"  âŒ ì»¬ëŸ¼ ëˆ„ë½ ({filename}): {df.columns}\")\n",
    "                     continue\n",
    "\n",
    "                raw_ppg = df['PPG'].values\n",
    "                raw_temp = df['temperature'].values\n",
    "                \n",
    "                # ì „ì²˜ë¦¬: Detrending -> 4Hz Low-pass Filter\n",
    "                processed_ppg = self.preprocess_ppg(raw_ppg)\n",
    "                \n",
    "                # ì˜¨ë„ ì •ê·œí™” (Min-Max Scaling: 25~40ë„ ê¸°ì¤€)\n",
    "                processed_temp = (raw_temp - 25.0) / (40.0 - 25.0) \n",
    "\n",
    "                # 4. ìŠ¬ë¼ì´ë”© ìœˆë„ìš°\n",
    "                num_windows = (len(processed_ppg) - self.window_size) // self.stride\n",
    "                \n",
    "                if num_windows <= 0:\n",
    "                    continue\n",
    "\n",
    "                file_samples = 0\n",
    "                for i in range(num_windows):\n",
    "                    start = i * self.stride\n",
    "                    end = start + self.window_size\n",
    "                    \n",
    "                    ppg_window = processed_ppg[start:end]\n",
    "                    temp_window = processed_temp[start:end]\n",
    "                    \n",
    "                    # (Optional) ì´ìƒì¹˜ ì œê±° (PPG Z-score > 5)\n",
    "                    if np.max(np.abs(ppg_window)) > 5:\n",
    "                        continue\n",
    "                        \n",
    "                    self.samples_ppg.append(ppg_window)\n",
    "                    self.samples_temp.append(temp_window)\n",
    "                    self.labels.append(label)\n",
    "                    file_samples += 1\n",
    "                \n",
    "                print(f\"  âœ… User {user_num} (Label {label}): {file_samples} windows loaded.\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  âŒ ë°ì´í„° ë¡œë“œ ì—ëŸ¬ ({filename}): {e}\")\n",
    "\n",
    "        # ë¦¬ìŠ¤íŠ¸ -> Numpy -> Tensor\n",
    "        self.samples_ppg = np.array(self.samples_ppg, dtype=np.float32)\n",
    "        self.samples_temp = np.array(self.samples_temp, dtype=np.float32)\n",
    "        self.labels = np.array(self.labels, dtype=np.int64)\n",
    "        \n",
    "        # ì°¨ì› í™•ì¥: (N, 1, Length)\n",
    "        if len(self.labels) > 0:\n",
    "            self.samples_ppg = np.expand_dims(self.samples_ppg, axis=1)\n",
    "            self.samples_temp = np.expand_dims(self.samples_temp, axis=1)\n",
    "\n",
    "        print(f\"ğŸ‰ ì „ì²´ ë°ì´í„° ë¡œë“œ ì™„ë£Œ! ì´ ìƒ˜í”Œ ìˆ˜: {len(self.labels)}\")\n",
    "\n",
    "    def preprocess_ppg(self, signal_data):\n",
    "        # 1. Detrending\n",
    "        detrended = signal.detrend(signal_data)\n",
    "        # 2. Low-pass Filter (4Hz)\n",
    "        nyquist = 0.5 * self.fs\n",
    "        cutoff = 4.0 / nyquist\n",
    "        b, a = signal.butter(4, cutoff, btype='low')\n",
    "        filtered = signal.filtfilt(b, a, detrended)\n",
    "        # 3. Z-score Normalization\n",
    "        normalized = (filtered - np.mean(filtered)) / (np.std(filtered) + 1e-6)\n",
    "        return normalized\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (torch.from_numpy(self.samples_ppg[idx]), \n",
    "                torch.from_numpy(self.samples_temp[idx])), torch.tensor(self.labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ba181f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ ë°ì´í„° ë¡œë”© ì‹œì‘... (ì´ 18ê°œ íŒŒì¼ ê°ì§€)\n",
      "  âœ… User 8 (Label 7): 135353 windows loaded.\n",
      "  âœ… User 2 (Label 1): 113091 windows loaded.\n",
      "  âœ… User 1 (Label 0): 113455 windows loaded.\n",
      "  âœ… User 12 (Label 11): 116450 windows loaded.\n",
      "  âœ… User 6 (Label 5): 86729 windows loaded.\n",
      "  âœ… User 3 (Label 2): 122985 windows loaded.\n",
      "  âœ… User 4 (Label 3): 75689 windows loaded.\n",
      "  âœ… User 14 (Label 13): 133755 windows loaded.\n",
      "  âœ… User 6 (Label 5): 31017 windows loaded.\n",
      "  âœ… User 13 (Label 12): 132584 windows loaded.\n",
      "  âœ… User 7 (Label 6): 121931 windows loaded.\n",
      "  âœ… User 16 (Label 15): 127971 windows loaded.\n",
      "  âœ… User 5 (Label 4): 122964 windows loaded.\n",
      "  âœ… User 15 (Label 14): 122069 windows loaded.\n",
      "  âœ… User 4 (Label 3): 56395 windows loaded.\n",
      "  âœ… User 11 (Label 10): 121235 windows loaded.\n",
      "  âœ… User 9 (Label 8): 133277 windows loaded.\n",
      "  âœ… User 10 (Label 9): 114894 windows loaded.\n",
      "ğŸ‰ ì „ì²´ ë°ì´í„° ë¡œë“œ ì™„ë£Œ! ì´ ìƒ˜í”Œ ìˆ˜: 1981844\n",
      "\n",
      "--- Batch Shape Check ---\n",
      "PPG Input Shape : torch.Size([64, 1, 300])\n",
      "Temp Input Shape: torch.Size([64, 1, 300])\n",
      "Label Shape     : torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data_folder = \"./data/PPG_ECG_Data\"\n",
    "    \n",
    "    # ìœˆë„ìš° í¬ê¸° 300 (ë…¼ë¬¸ ê¸°ì¤€), ìŠ¤íŠ¸ë¼ì´ë“œ 50 (ê²¹ì³ì„œ ë°ì´í„° ì¦ê°• íš¨ê³¼)\n",
    "    dataset = MultiModalDataset(data_folder, window_size=300, stride=50)\n",
    "    \n",
    "    # DataLoader ìƒì„±\n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    # ë°ì´í„° í˜•ìƒ í™•ì¸\n",
    "    if len(dataset) > 0:\n",
    "        (ppg, temp), label = next(iter(dataloader))\n",
    "        print(\"\\n--- Batch Shape Check ---\")\n",
    "        print(f\"PPG Input Shape : {ppg.shape}\")   # (64, 1, 300)\n",
    "        print(f\"Temp Input Shape: {temp.shape}\")  # (64, 1, 300)\n",
    "        print(f\"Label Shape     : {label.shape}\") # (64,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e550c279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ==========================================\n",
    "# 1. SSM Block (S4 Simplified)\n",
    "# ==========================================\n",
    "class S4Block(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1):\n",
    "        super(S4Block, self).__init__()\n",
    "        # ì‹œê³„ì—´ì˜ ì‹œê°„ì  íŠ¹ì§•(Long-range dependency)ì„ ì¡ëŠ” í•µì‹¬ ë ˆì´ì–´\n",
    "        # ë…¼ë¬¸ì˜ ë³µì¡í•œ S4 ìˆ˜ì‹ì„ 1D Convì™€ Gating ë©”ì»¤ë‹ˆì¦˜ìœ¼ë¡œ ê·¼ì‚¬í•˜ì—¬ êµ¬í˜„\n",
    "        self.conv1d = nn.Conv1d(d_model, d_model, kernel_size=3, padding=1, groups=d_model)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.activation = nn.SiLU() # Mamba/S4ì—ì„œ ì£¼ë¡œ ì“°ëŠ” í™œì„±í™” í•¨ìˆ˜\n",
    "        self.output_proj = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (Batch, Length, d_model)\n",
    "        residual = x\n",
    "        \n",
    "        # 1. Time-mixing (Conv1D)\n",
    "        # (B, L, D) -> (B, D, L)ë¡œ ë³€í™˜ í›„ Conv ì ìš©\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.conv1d(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        \n",
    "        # 2. Gating\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        # 3. Channel-mixing (Linear)\n",
    "        x = self.output_proj(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # 4. Residual & Norm\n",
    "        x = self.norm(x + residual)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "283a4df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. SSM Encoder\n",
    "# ==========================================\n",
    "class SSMEncoder(nn.Module):\n",
    "    def __init__(self, input_len=300, d_model=64, num_layers=2):\n",
    "        super(SSMEncoder, self).__init__()\n",
    "        \n",
    "        # ì…ë ¥: (Batch, 1, 300) -> (Batch, 300, 64) ì°¨ì› í™•ì¥\n",
    "        self.input_projection = nn.Linear(1, d_model)\n",
    "        \n",
    "        # ë…¼ë¬¸ëŒ€ë¡œ 2ê°œì˜ SSM ë ˆì´ì–´ ì ì¸µ\n",
    "        self.layers = nn.ModuleList([\n",
    "            S4Block(d_model) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # ì‹œí€€ìŠ¤ë¥¼ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ì••ì¶• (Pooling)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (Batch, 1, Length)\n",
    "        \n",
    "        # (B, 1, L) -> (B, L, 1) -> (B, L, d_model)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.input_projection(x)\n",
    "        \n",
    "        # SSM Layers í†µê³¼\n",
    "        for layer in self.layers:\n",
    "            x = layer(x) # (B, L, d_model)\n",
    "            \n",
    "        # Global Pooling: (B, L, D) -> (B, D, 1) -> (B, D)\n",
    "        x_pooled = self.pool(x.transpose(1, 2)).squeeze(-1)\n",
    "        \n",
    "        return x_pooled, x # Poolingëœ ë²¡í„°ì™€ ì „ì²´ ì‹œí€€ìŠ¤ ëª¨ë‘ ë°˜í™˜\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54fbf4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. ì „ì²´ ëª¨ë¸ (Fusion & Classifier)\n",
    "# ==========================================\n",
    "class CrossAttentionFusion(nn.Module):\n",
    "    def __init__(self, num_users=16, d_model=64, num_heads=4):\n",
    "        super(CrossAttentionFusion, self).__init__()\n",
    "        \n",
    "        # ë“€ì–¼ ì¸ì½”ë” (PPGìš©, Tempìš©)\n",
    "        self.ppg_encoder = SSMEncoder(d_model=d_model)\n",
    "        self.temp_encoder = SSMEncoder(d_model=d_model)\n",
    "        \n",
    "        # Cross-Modal Attention\n",
    "        self.cross_att = nn.MultiheadAttention(d_model, num_heads=num_heads, batch_first=True)\n",
    "        \n",
    "        self.norm_p = nn.LayerNorm(d_model)\n",
    "        self.norm_t = nn.LayerNorm(d_model)\n",
    "        \n",
    "        # Fusion & Classifier\n",
    "        self.fusion_fc = nn.Linear(d_model, d_model)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(d_model // 2, num_users)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_ppg, x_temp):\n",
    "        # 1. ì¸ì½”ë”©\n",
    "        z_p, seq_p = self.ppg_encoder(x_ppg) # z: (B, D), seq: (B, L, D)\n",
    "        z_t, seq_t = self.temp_encoder(x_temp)\n",
    "        \n",
    "        # 2. Cross-Attentionì„ ìœ„í•œ ì°¨ì› ì¡°ì • (B, 1, D)\n",
    "        query_p = z_p.unsqueeze(1)\n",
    "        query_t = z_t.unsqueeze(1)\n",
    "        \n",
    "        # PPGê°€ Tempë¥¼ ì°¸ì¡°í•˜ì—¬ ë³´ì •\n",
    "        attn_out_p, _ = self.cross_att(query_p, query_t, query_t)\n",
    "        z_p_refined = self.norm_p(z_p + attn_out_p.squeeze(1))\n",
    "        \n",
    "        # Tempê°€ PPGë¥¼ ì°¸ì¡°í•˜ì—¬ ë³´ì •\n",
    "        attn_out_t, _ = self.cross_att(query_t, query_p, query_p)\n",
    "        z_t_refined = self.norm_t(z_t + attn_out_t.squeeze(1))\n",
    "        \n",
    "        # 3. Fusion (Element-wise Addition)\n",
    "        z_fused = z_p_refined + z_t_refined\n",
    "        z_fused = F.relu(self.fusion_fc(z_fused))\n",
    "        \n",
    "        # 4. Classification\n",
    "        logits = self.classifier(z_fused)\n",
    "        \n",
    "        return logits, z_p_refined, z_t_refined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aacbd588",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlignmentLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super(AlignmentLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, z_a, z_b):\n",
    "        # z_a, z_b: (Batch, D)\n",
    "        # Cosine Similarity ê³„ì‚°\n",
    "        z_a = F.normalize(z_a, dim=1)\n",
    "        z_b = F.normalize(z_b, dim=1)\n",
    "        \n",
    "        # (B, D) @ (D, B) -> (B, B) ìœ ì‚¬ë„ í–‰ë ¬\n",
    "        logits = torch.matmul(z_a, z_b.T) / self.temperature\n",
    "        \n",
    "        # ì •ë‹µ: ëŒ€ê°ì„  ìš”ì†Œ (ìê¸° ìì‹ ê³¼ì˜ ìŒ)\n",
    "        labels = torch.arange(z_a.size(0)).to(z_a.device)\n",
    "        \n",
    "        return self.ce_loss(logits, labels)\n",
    "\n",
    "class SpreadControlLoss(nn.Module):\n",
    "    def __init__(self, threshold=0.001):\n",
    "        super(SpreadControlLoss, self).__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def forward(self, z):\n",
    "        # íŠ¹ì§• ë²¡í„°ë“¤ì˜ ë¶„ì‚°ì´ ë„ˆë¬´ ì»¤ì§€ì§€ ì•Šë„ë¡ ì œì–´\n",
    "        z = F.normalize(z, dim=1)\n",
    "        var = torch.var(z, dim=0).mean()\n",
    "        # ë¶„ì‚°ì´ thresholdë³´ë‹¤ í¬ë©´ í˜ë„í‹°\n",
    "        loss = F.relu(var - self.threshold)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b8145e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ í•™ìŠµ ì¥ì¹˜: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15:   0%|          | 0/30967 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30967/30967 [16:25<00:00, 31.44it/s, Loss=2.0711, Acc=20.13%, Cls=2.0473]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ¨ Epoch 1 Summary - Avg Loss: 2.6212, Accuracy: 20.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30967/30967 [16:26<00:00, 31.38it/s, Loss=2.7368, Acc=22.34%, Cls=2.7006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ¨ Epoch 2 Summary - Avg Loss: 2.4399, Accuracy: 22.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30967/30967 [16:10<00:00, 31.91it/s, Loss=2.4567, Acc=23.05%, Cls=2.4496]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ¨ Epoch 3 Summary - Avg Loss: 2.3904, Accuracy: 23.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30967/30967 [15:52<00:00, 32.51it/s, Loss=2.1759, Acc=23.61%, Cls=2.1649]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ¨ Epoch 4 Summary - Avg Loss: 2.3604, Accuracy: 23.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30967/30967 [15:48<00:00, 32.67it/s, Loss=2.5730, Acc=24.03%, Cls=2.5689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ¨ Epoch 5 Summary - Avg Loss: 2.3444, Accuracy: 24.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30967/30967 [16:09<00:00, 31.93it/s, Loss=2.0633, Acc=24.33%, Cls=2.0479]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ¨ Epoch 6 Summary - Avg Loss: 2.3332, Accuracy: 24.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30967/30967 [16:11<00:00, 31.88it/s, Loss=2.6937, Acc=24.57%, Cls=2.6876]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ¨ Epoch 7 Summary - Avg Loss: 2.3242, Accuracy: 24.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30967/30967 [16:10<00:00, 31.92it/s, Loss=2.7746, Acc=24.75%, Cls=2.7655]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ¨ Epoch 8 Summary - Avg Loss: 2.3168, Accuracy: 24.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30967/30967 [16:25<00:00, 31.42it/s, Loss=2.2572, Acc=24.94%, Cls=2.2366]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ¨ Epoch 9 Summary - Avg Loss: 2.3091, Accuracy: 24.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30967/30967 [16:14<00:00, 31.77it/s, Loss=2.0148, Acc=25.10%, Cls=2.0132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ¨ Epoch 10 Summary - Avg Loss: 2.3029, Accuracy: 25.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30967/30967 [16:28<00:00, 31.34it/s, Loss=2.6024, Acc=25.27%, Cls=2.5939]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ¨ Epoch 11 Summary - Avg Loss: 2.2942, Accuracy: 25.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30967/30967 [16:25<00:00, 31.43it/s, Loss=2.2486, Acc=25.39%, Cls=2.2419]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ¨ Epoch 12 Summary - Avg Loss: 2.2889, Accuracy: 25.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30967/30967 [16:25<00:00, 31.43it/s, Loss=2.0396, Acc=25.52%, Cls=2.0336]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ¨ Epoch 13 Summary - Avg Loss: 2.2851, Accuracy: 25.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30967/30967 [16:19<00:00, 31.62it/s, Loss=2.6416, Acc=25.62%, Cls=2.6389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ¨ Epoch 14 Summary - Avg Loss: 2.2807, Accuracy: 25.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30967/30967 [16:02<00:00, 32.16it/s, Loss=2.0432, Acc=25.72%, Cls=2.0405]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ¨ Epoch 15 Summary - Avg Loss: 2.2774, Accuracy: 25.72%\n",
      "ğŸ ëª¨ë“  í•™ìŠµ ì™„ë£Œ!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm  # Jupyter/Console ìë™ ê°ì§€\n",
    "\n",
    "# ==========================================\n",
    "# ì„¤ì • (Hyperparameters)\n",
    "# ==========================================\n",
    "NUM_USERS = 16  \n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LAMBDA_A = 0.5  \n",
    "LAMBDA_S = 0.01 \n",
    "LR = 0.001\n",
    "EPOCHS = 15   \n",
    "\n",
    "print(f\"ğŸš€ í•™ìŠµ ì¥ì¹˜: {DEVICE}\")\n",
    "\n",
    "# ==========================================\n",
    "# ëª¨ë¸ ë° í•™ìŠµ ì¤€ë¹„\n",
    "# ==========================================\n",
    "model = CrossAttentionFusion(num_users=NUM_USERS).to(DEVICE)\n",
    "\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "criterion_align = AlignmentLoss()\n",
    "criterion_spread = SpreadControlLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# ==========================================\n",
    "# í•™ìŠµ ì‹¤í–‰\n",
    "# ==========================================\n",
    "model.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    # DataLoaderë¥¼ tqdmìœ¼ë¡œ ê°ì‹¸ì„œ ì§„í–‰ë¥  ë°” ìƒì„±\n",
    "    # desc: ë°” ì™¼ìª½ì— í‘œì‹œë  ì„¤ëª… (Epoch ë²ˆí˜¸)\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=True)\n",
    "    \n",
    "    for batch_idx, ((ppg, temp), labels) in enumerate(progress_bar):\n",
    "        # ë°ì´í„° GPUë¡œ ì´ë™\n",
    "        ppg = ppg.to(DEVICE)\n",
    "        temp = temp.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 1. Forward\n",
    "        outputs, z_p, z_t = model(ppg, temp)\n",
    "        \n",
    "        # 2. Loss ê³„ì‚°\n",
    "        loss_cls = criterion_cls(outputs, labels)\n",
    "        \n",
    "        # ì •ë ¬ ì†ì‹¤ (Alignment: ì–‘ë°©í–¥)\n",
    "        loss_align = criterion_align(z_p, z_t) + criterion_align(z_t, z_p)\n",
    "        \n",
    "        # ë¶„ì‚° ì œì–´ ì†ì‹¤ (Spread)\n",
    "        loss_spread = criterion_spread(z_p) + criterion_spread(z_t)\n",
    "        \n",
    "        # ìµœì¢… Loss í•©ì‚°\n",
    "        loss = loss_cls + (LAMBDA_A * loss_align) + (LAMBDA_S * loss_spread)\n",
    "        \n",
    "        # 3. Backward & Update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # í†µê³„ ì—…ë°ì´íŠ¸\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # ì‹¤ì‹œê°„ ì •í™•ë„ ê³„ì‚°\n",
    "        current_acc = 100 * correct / total_samples\n",
    "        \n",
    "        # TQDM ë°” ìš°ì¸¡ì— ì‹¤ì‹œê°„ ì •ë³´ í‘œì‹œ (Loss, Accuracy)\n",
    "        progress_bar.set_postfix({\n",
    "            'Loss': f\"{loss.item():.4f}\",\n",
    "            'Acc': f\"{current_acc:.2f}%\",\n",
    "            'Cls': f\"{loss_cls.item():.4f}\" # ë¶„ë¥˜ Lossë§Œ ë”°ë¡œ ë³´ê³  ì‹¶ë‹¤ë©´ ì¶”ê°€\n",
    "        })\n",
    "\n",
    "    # ì—í­ ì¢…ë£Œ í›„ í‰ê·  ê¸°ë¡ ì¶œë ¥\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    final_acc = 100 * correct / total_samples\n",
    "    print(f\"âœ¨ Epoch {epoch+1} Summary - Avg Loss: {avg_loss:.4f}, Accuracy: {final_acc:.2f}%\")\n",
    "\n",
    "print(\"ğŸ ëª¨ë“  í•™ìŠµ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd038208",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
